[{"authors":["ben"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667167623,"objectID":"bf008f22d9b0754cde4f6972811c28b7","permalink":"https://umichstatistics.github.io/ComputingClub/authors/ben/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/ben/","section":"authors","summary":"","tags":null,"title":"Ben Brennan","type":"authors"},{"authors":["derek"],"categories":null,"content":"About me ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667167623,"objectID":"bc34d76bc3e159b0c10dc7a9fb6aef07","permalink":"https://umichstatistics.github.io/ComputingClub/authors/dan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/dan/","section":"authors","summary":"About me ","tags":null,"title":"Dan Kessler","type":"authors"},{"authors":["derek"],"categories":null,"content":"About me ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667167623,"objectID":"26db54e84a45b767b8ee836b1c5f8134","permalink":"https://umichstatistics.github.io/ComputingClub/authors/derek/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/derek/","section":"authors","summary":"About me ","tags":null,"title":"Derek Hansen","type":"authors"},{"authors":["jregier"],"categories":null,"content":"About me I’m an applied statistician working on problems in astronomy and genomics. Graphical models, variational inference, and deep learning are some of the statistical tools I use.\nPreviously, I was a statistics PhD student at UC Berkeley and a postdoc in Michael Jordan’s research group. For more about me, please see my publications and my CV.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1570078435,"objectID":"a47974f9e0ec82ef034bbaf066bfb35e","permalink":"https://umichstatistics.github.io/ComputingClub/authors/jregier/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/jregier/","section":"authors","summary":"About me I’m an applied statistician working on problems in astronomy and genomics. Graphical models, variational inference, and deep learning are some of the statistical tools I use.\nPreviously, I was a statistics PhD student at UC Berkeley and a postdoc in Michael Jordan’s research group. For more about me, please see my publications and my CV.","tags":null,"title":"Jeffrey Regier","type":"authors"},{"authors":["michael"],"categories":null,"content":"About me ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1579664110,"objectID":"509d4a3df3ec008cfbb7dc4951a619f0","permalink":"https://umichstatistics.github.io/ComputingClub/authors/michael/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/michael/","section":"authors","summary":"About me ","tags":null,"title":"Michael Law","type":"authors"},{"authors":["rob"],"categories":null,"content":"About me ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667167623,"objectID":"1e69b33059cc9342e33da675bf1c651a","permalink":"https://umichstatistics.github.io/ComputingClub/authors/rob/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/rob/","section":"authors","summary":"About me ","tags":null,"title":"Rob Trangucci","type":"authors"},{"authors":["simon"],"categories":null,"content":"About me I currently am a first year Ph.D. Student at the University of Michigan. My research interest are broadly contained in computational statistics. In particular, penalized regression and variable selection problems as well as approximate Bayesian inference and MCMC methods are all of interest to me. Previously, I worked as a Data Science intern at the Ubisoft Montreal User Research Lab on online skill rating using approximate Bayesian inference. I did a Master’s at the University of Montreal and my thesis focused on an adaptive Multiple-Try Metropolis algorithm aimed at sampling from complex distributions.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667167623,"objectID":"39676266dc03f7a9ebc998657bf4cd2d","permalink":"https://umichstatistics.github.io/ComputingClub/authors/simon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/simon/","section":"authors","summary":"About me I currently am a first year Ph.D. Student at the University of Michigan. My research interest are broadly contained in computational statistics. In particular, penalized regression and variable selection problems as well as approximate Bayesian inference and MCMC methods are all of interest to me. Previously, I worked as a Data Science intern at the Ubisoft Montreal User Research Lab on online skill rating using approximate Bayesian inference. I did a Master’s at the University of Montreal and my thesis focused on an adaptive Multiple-Try Metropolis algorithm aimed at sampling from complex distributions.","tags":null,"title":"Simon Fontaine","type":"authors"},{"authors":["admin"],"categories":null,"content":"About us This page is for the Computing Club overseen by the UM Stats PhD Computing Committee. Information about meeting times and presented topics will be posted here.\nThe only guiding principle is that the topic should have some potential application to a Statistics research workload, which leaves a broad range of topics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1570078435,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://umichstatistics.github.io/ComputingClub/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/admin/","section":"authors","summary":"About us This page is for the Computing Club overseen by the UM Stats PhD Computing Committee. Information about meeting times and presented topics will be posted here.\nThe only guiding principle is that the topic should have some potential application to a Statistics research workload, which leaves a broad range of topics.","tags":null,"title":"Statistics Computing Club","type":"authors"},{"authors":["username"],"categories":null,"content":"About me ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1570209932,"objectID":"d77af74b00d7d7e6b445db2a76fc0d96","permalink":"https://umichstatistics.github.io/ComputingClub/authors/blank/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/blank/","section":"authors","summary":"About me ","tags":null,"title":"YOUR-HAME-HERE","type":"authors"},{"authors":["xiping"],"categories":null,"content":"About me ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1570078435,"objectID":"2dee3fb3bf4f399c6dd125cf65a952be","permalink":"https://umichstatistics.github.io/ComputingClub/authors/ziping/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/ComputingClub/authors/ziping/","section":"authors","summary":"About me ","tags":null,"title":"Ziping Xu","type":"authors"},{"authors":null,"categories":null,"content":"Goal\nPersonal websites that are easy to create and maintain Yet flexible and beautiful Free Two frameworks\nhugo and jekyll Static sites generators Content written in Markdown, some configuration in YAML Build the corresponding html pages Various themes for your applications blogs, portfolios, research group, résumé, project documentation, etc. Hosting\nGitHub Pages Automatic build with GitHub Actions We want to avoid\nwriting html lots of manipulations to update your website Hugo and Academic theme with GitHub Actions See demo website\nStructure:\nfront page organized in widgets excellent management for publications, talks, etc tags, projects, sorting, featured, links, etc. allows math without any work\nOther themes: lots for blogging, project docs; see also Resume, Avicenna and the Academic variations (Résumé, Research Group, Online course)\nSetting up Hugo See this guide\nSetting up Git, GitHub and local repository (Inspired from this guide)\nInstall git\nWe will create two repos:\nsome-name: will hold content (Md, YAML, reference to theme); should be a fork of the Academic theme \u0026lt;your-username\u0026gt;.github.io: will hold the actual website (html, css, js) Clone locally and initialize submodules (reference to theme)\ngit clone https://github.com/\u0026lt;USERNAME\u0026gt;/my-wowchemy-site.git My_Website cd My_Website git submodule update --init --recursive Add the build repo as a submodule to the content repo:\ngit submodule add -f -b master https://github.com/\u0026lt;USERNAME\u0026gt;/\u0026lt;USERNAME\u0026gt;.github.io.git public You\u0026rsquo;ll probably get some warnings, you can ignore them.\nFirst build Change base URL in config/_default/config.yaml\nbaseurl = \u0026#34;https://\u0026lt;USERNAME\u0026gt;.github.io/\u0026#34; Serve locally\nhugo server Check your website at the address privided (e.g., http://localhost:1313/)\nFirst build\nhugo Now check that public has been populated\nDeploy to GitHub From the content local repo, commit and push (this only pushes the content):\ngit add . git commit -m \u0026#34;Initial commit\u0026#34; git push -u origin master Then push the built website\ncd public git add . git commit -m \u0026#34;First build\u0026#34; git push origin master cd .. Check out the remote repo\nWait for GitHub to apply changes, and check out your new website!\n\u0026lt;USERNAME\u0026gt;.github.io Update workflow To get any cahnge on the website, you need to update the remote repo \u0026lt;USERNAME\u0026gt;.github.io; changing the remote content repo will do nothing. Here are two approahces:\nLocal build, push both sequenceDiagram participant lc as Local Content participant lw as Local Website participant rc as Remote Content participant rw as Remote Website rc -\u0026gt;\u0026gt; lc: pull lc -\u0026gt;\u0026gt; lc: Update content lc -\u0026gt;\u0026gt; lw: Build with hugo lc -\u0026gt;\u0026gt; lc: Update content lc -\u0026gt;\u0026gt; lw: Build with hugo lc -\u0026gt;\u0026gt; rc: push lw -\u0026gt;\u0026gt; rw: push Automatic deployment With proper automatization, updating can be as simple as:\nsequenceDiagram participant lc as Local Content participant lw as Local Website participant rc as Remote Content participant rw as Remote Website rc -\u0026gt;\u0026gt; lc: pull lc -\u0026gt;\u0026gt; lc: Update content lc -\u0026gt;\u0026gt; rc: push rc --\u0026gt;\u0026gt; rw: Build with hugo and push (automatic) In particular, you don\u0026rsquo;t even need hugo on your machine, only git!\nThis also allows to edit directly on GitHub (useful for typos and small updates!). Don\u0026rsquo;t forget to pull locally, though!\n(Based on this tutorial)\nTo achieve this, we need to use GitHub Actions.\nFirst, we need to create a public/private key pair (see this guide)\nssh-keygen -t rsa -b 4096 -C \u0026#34;$(git config user.email)\u0026#34; -f gh-pages -N \u0026#34;\u0026#34; # You will get 2 files: # gh-pages.pub (public key) # gh-pages (private key) Go to repository settings:\nIn build repo: Go to Deploy Keys and add your public key with Allow write access In content repo: Go to Secrets and add your private key as ACTIONS_DEPLOY_KEY In the /.github/workflows/ folder of the content repo, add the following gh-pages.yml file (can also be done in the Actions tab on the GitHub website):\nname: GitHub Pages with Hugo on: push: branches: - master jobs: build-deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; extended: true - uses: actions/cache@v2 with: path: /tmp/hugo_cache key: ${{ runner.os }}-hugomod-${{ hashFiles(\u0026#39;**/go.sum\u0026#39;) }} restore-keys: | ${{ runner.os }}-hugomod- - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} external_repository: fontaine618/fontaine618.github.io publish_branch: main publish_dir: ./public Hugo Academic and BibTeX Creating content may be long, especially if you have many publications (one file per publications and requires to fill in entries). Fortunately, there exist a tool taking a .bib file doing everything for you:\nSee this tutorial\nCustomization See the documentation\nJekyll and GitHub Pages Jekyll works very similarly to hugo, but has slightly better GitHub Actions support by the community. Templates are generally simpler than Academic Hugo, however.\nPreparation Satisfy all requirements Select a template: we will use al-folio as it has a nice publications features. (see the github repo for examples and features) Fork the repo Rename to \u0026lt;USERNAME\u0026gt;.github.io Local build Clone, install and build:\ngit clone https://github.com/\u0026lt;USERNAME\u0026gt;/\u0026lt;USERNAME\u0026gt;.github.io.git cd \u0026lt;USERNAME\u0026gt;.github.io bundle install bundle exec jekyll serve You can check out your local website at the specified address (e.g., http://127.0.0.1:4000/)\nlike hugo the serve command listens to changes so it will dynamically update! Deploy on GitHub Pages In _config.yml, change url to\nurl: https://\u0026lt;USERNAME\u0026gt;.github.io/ and set baseurl to nothing\nbaseurl: Commit and push your website\nOn the GitHub website:\nActions \u0026gt; Enable GitHub Actions (the al-folio comes with Actions!) Repository settings \u0026gt; Pages \u0026gt; set branch to gh-pages Wait for GitHub to apply changes, and check out your new website!\n\u0026lt;USERNAME\u0026gt;.github.io Other templates may not have built-in actions, you can look at this tutorial (note that you no longer need to create the GITHUB_TOKEN).\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1634234703,"objectID":"c5eaf2dc1511d7c110fa793661a741c0","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/website/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/ComputingClub/workshops/website/","section":"workshops","summary":"Creating and hosting your personal website","tags":null,"title":"Creating and hosting your personal website","type":"docs"},{"authors":null,"categories":null,"content":"This website is powered the Academic theme for Hugo. The documentation they provide is quite extensive, so we summarize some of the important features relevant to the current website and present workflow ideas on how to update the website.\nHugo and Markdown While the website consists of html source interpreted by the visitor\u0026rsquo;s browser, its content is generated from Markdown. Hugo acts as an interpreter and compiler: it translates the file structure, the Markdown files and some configuration files (yaml or toml) into the html files visible to the visitor.\nRepository description The website is hosted on GitHub Pages. The static contents of the website appears in the docs folder of the UmichStatistics GitHub organization repository ComputingClub. The other folders and files of the repository are used to generate the website: only the docs folder is necessary for the static website to be operational.\nDeployment Any change in the files outside of the docs folder will not affect the public website. In order for the changes to become public, it is necessary to deploy the website, i.e. to use Hugo to update the files in docs. Hence, anyone updating the website needs to run Hugo for the changes to appear. More details in Deployment\nThe maintainers are currently considerings ways to automatically deploy the website upon a push to the repository. More to come\u0026hellip;\nExternal resources Academic Hugo Documentation Page Builder and widgets description Font Awesome Icons ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1569436453,"objectID":"989426793d2ad203cae764c09b8fff59","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/edit_site/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/ComputingClub/workshops/edit_site/","section":"workshops","summary":"A guide on how to add new content and modify the website.","tags":null,"title":"Editing the Club's website","type":"docs"},{"authors":null,"categories":null,"content":"What is Functional Programming? Functions are like those in mathematics: They always return the same output for a given input No side-effects (e.g. modification of global variables) Functions that satisfy (1-2) are called pure Functions are first-class objects which can be passed as arguments to other functions (a.k.a. functionals) There is no changing state as the program runs; values are assigned once as functions of other values and inputs Everyday example: Microsoft Excel (without any VBA scripting!) Why use functional programming? Through avoiding mutable state and composing pure functions, an FP program is also a pure function of its input This makes FP programs\u0026hellip; Modular Predictable Easier to test Avoid common pitfalls involving changing state (e.g. global variables) Why use functional programming? Natural functionals in the FP paradigm include \u0026hellip;\nmap: (where $f: X \\to Y$) $$((x_1, \u0026hellip;, x_n), f) \\to (f(x_1), \u0026hellip;, f(x_n)))$$\nfilter: (where $f$ is a predicate function $f:X \\to \\{0, 1\\}$) $$((x_1, \u0026hellip;, x_n), f) \\to (x_i : f(x_i) = 1)$$\nreduce: (where $f$ is an operator function $f:X \\times X \\to X$) $$((x_1, \u0026hellip;, x_n), f) \\to f(x_1, f(x_2, f(x_3, f(\u0026hellip;))))$$\nFunctional Programming in R R is multi-paradigm: it does not strictly adhere to FP principles, but it offers capability to use FP patterns Examples in base R include: Map, lapply, sapply, apply, vapply, mapply Reduce Filter The purrr package by Hadley Wickham et al improves the the functional programming tools to R which are syntactically consistent and type-safe. Mapping map is pretty much equivalent to lapply, but has some additional features library(purrr) my_sqrt \u0026lt;- function(x) sqrt(x) str(map(c(1,2,3,4,5), my_sqrt)) ## List of 5 ## $ : num 1 ## $ : num 1.41 ## $ : num 1.73 ## $ : num 2 ## $ : num 2.24 str(lapply(c(1,2,3,4,5), my_sqrt)) ## List of 5 ## $ : num 1 ## $ : num 1.41 ## $ : num 1.73 ## $ : num 2 ## $ : num 2.24 Mapping If we want an atomic double vector instead of a list, the map_dbl ensures we always receive that. sapply does the same thing in this particular instance, but we can run into problems\u0026hellip; str(map_dbl(c(1,2,3,4,5), my_sqrt)) ## num [1:5] 1 1.41 1.73 2 2.24 str(sapply(c(1,2,3,4,5), my_sqrt)) ## num [1:5] 1 1.41 1.73 2 2.24 Problem: sapply is not type-safe! Example: Our colleague worked hard to make my_sqrt handle any real number. They even overwrote the function my_sqrt to make the transition seamless! sqrt_general \u0026lt;- function(x) { if(x \u0026gt;= 0) sqrt(x) else return(paste0(sqrt(abs(x)), \u0026#34;i\u0026#34;)) } my_sqrt \u0026lt;- sqrt_general my_sqrt(5) ## [1] 2.236068 my_sqrt(-5) ## [1] \u0026#34;2.23606797749979i\u0026#34; Problem: sapply is not type-safe! str(sapply(c(1,2,3,4,5), my_sqrt)) ## num [1:5] 1 1.41 1.73 2 2.24 str(sapply(c(-1,2,-3,4,5), my_sqrt)) ## chr [1:5] \u0026#34;1i\u0026#34; \u0026#34;1.4142135623731\u0026#34; \u0026#34;1.73205080756888i\u0026#34; \u0026#34;2\u0026#34; ... This is a great way to propogate errors. We have no way to guarentee whether sapply will return a \u0026ldquo;double\u0026rdquo; vector or a \u0026ldquo;string\u0026rdquo; vector. map_dbl is type-safe! str(map_dbl(c(1,2,3,4,5), my_sqrt)) ## num [1:5] 1 1.41 1.73 2 2.24 try(str(map_dbl(c(-1,2,-3,4,5), my_sqrt))) ## Error : Can\u0026#39;t coerce element 1 from a character to a double The map_* family of functions allows us to explictly impose which type we expect the output vector to be. They \u0026ldquo;return an atomic vector of the indicated type (or die trying)\u0026rdquo; (documentation) map_chr is type-safe! map_chr(c(1,2,3,4,5), my_sqrt) ## [1] \u0026#34;1.000000\u0026#34; \u0026#34;1.414214\u0026#34; \u0026#34;1.732051\u0026#34; \u0026#34;2.000000\u0026#34; \u0026#34;2.236068\u0026#34; map_chr(c(-1,2,-3,4,5), my_sqrt) ## [1] \u0026#34;1i\u0026#34; \u0026#34;1.414214\u0026#34; \u0026#34;1.73205080756888i\u0026#34; ## [4] \u0026#34;2.000000\u0026#34; \u0026#34;2.236068\u0026#34; Suppose our colleague convinced our team lead that we should work exclusively with strings to accomodate complex numbers We use map_chr to reflect that now we want the output to be a character vector. No errors now because both doubles and characters can be coerced to double. map_* is type-safe! sapply implicitly coerces to an atomic vector in the most general unit in the output for \u0026ldquo;convenience\u0026rdquo;, but this is very prone to unexpected errors. Most of the time, it is better to be explicit to catch any errors early and keep type stability. Can also use _lgl for logical, _int for integer, _raw for raw type, _dfr and _dfc for data-table columns and rows. Some more cool features of map - anonymous functions Can construct function in the argument using symbol notation map_dbl(c(1,2,3,4,5), ~.x^2 + .x + sin(.x)) ## [1] 2.841471 6.909297 12.141120 19.243198 29.041076 Some more cool features of map - multiple arguments Can use map2_* for 2 argument functions; pmap_* for n-argument functions The $i$th positional argument can be referenced with ..i syntax. map2_dbl(c(1,2,3,4,5), c(5,6,8,9,11), ~.x^2 + .y^2 + sin(.x)) ## [1] 26.84147 40.90930 73.14112 96.24320 145.04108 pmap_dbl(list(1:5, 11:15, 21:25), ~..1 + ..2 + ..3) ## [1] 33 36 39 42 45 pmap_dbl(list(1:5, 11:15, 21:25), function(x,y,z) x+y+z) ## [1] 33 36 39 42 45 Some more cool features of map - imap Can use imap if the names of the input list/vector are important. imap_*(x, f(x,y)) is equivalent to map2_*(x, names(x), f(x,y)) The type dfr indicates that we expect the function to output a DataFrame Row, which are then bound row-wise into a single dataframe. library(dplyr) midterm_grades \u0026lt;- c(Dan = 100, Derek = 20, Rob = 100) grade_tbl \u0026lt;- imap_dfr(midterm_grades, ~tibble(name = .y, grade = .x, pass = .x \u0026gt;= 50)) grade_tbl ## # A tibble: 3 x 3 ## name grade pass ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; ## 1 Dan 100 TRUE ## 2 Derek 20 FALSE ## 3 Rob 100 TRUE Some more cool features of map - map_if map_if allows for use of a predicate function (or a vector) to only apply to certain values. It always returns a list (since the input and output could be of different types). str(map_if(midterm_grades, !grade_tbl$pass, ~NA_real_)) ## List of 3 ## $ Dan : num 100 ## $ Derek: num NA ## $ Rob : num 100 str(map_if(midterm_grades, ~.x \u0026lt;= 50, ~\u0026#34;FAIL!!\u0026#34;)) ## List of 3 ## $ Dan : num 100 ## $ Derek: chr \u0026#34;FAIL!!\u0026#34; ## $ Rob : num 100 Some more cool features of map - map_if modify_if``` is the same as map_if`, but enforces that the type is the same as the input str(modify_if(midterm_grades, ~.x \u0026lt;= 50, ~NA_real_)) ## Named num [1:3] 100 NA 100 ## - attr(*, \u0026#34;names\u0026#34;)= chr [1:3] \u0026#34;Dan\u0026#34; \u0026#34;Derek\u0026#34; \u0026#34;Rob\u0026#34; try(str(modify_if(midterm_grades, ~.x \u0026lt;= 50, ~\u0026#34;FAIL!!\u0026#34;))) ## Error : Can\u0026#39;t coerce element 1 from a character to a double keep and discard ## Only keep students who passed keep(midterm_grades, ~.x \u0026gt;= 50) ## Dan Rob ## 100 100 ## Remove students who passed to get a list of students on notice discard(midterm_grades, grade_tbl$pass) ## Derek ## 20 purrr in the wild - succinctly extract results from different models library(dplyr) library(magrittr) aic_bic_tbl \u0026lt;- list( `Binary Poverty Indicator Interaction` = logis_res_census_binpoor, `Poverty Rate Interaction` = logis_res_census, `Income Interaction` = logis_res_census_inc_interact, `No Income` = logis_res_census_noincome, `No Poverty Rate` = logis_res_census_nopoor ) %\u0026gt;% map2_dfr(names(.), ~tibble(model = .y, aic = AIC(.x), bic = BIC(.x))) %\u0026gt;% arrange(aic) aic_bic_tbl Example directly from my applied qual. (Could have used imap_dfr!) purrr was designed by the same authors as dplyr and plays nicely with other tidyverse functions (including the pipe object %\u0026gt;%). purrr in the wild - reduce to best model best_model \u0026lt;- list( `Binary Poverty Indicator Interaction` = logis_res_census_binpoor, `Poverty Rate Interaction` = logis_res_census, `Income Interaction` = logis_res_census_inc_interact, `No Income` = logis_res_census_noincome, `No Poverty Rate` = logis_res_census_nopoor ) %\u0026gt;% reduce(~ifelse(BIC(.x) \u0026lt; BIC(.y), .y, .x)) reduce function applies an operator function to reduce a vector to one value Illustrating example, but in reality it would be more efficient to use which.max(aic_bic_tbl$bic) (because it uses C code and more efficient algorithm) Conclusions Through the Functional Programming (FP) paradigm, purrr allows for more concise and error-robust R coding patterns Allows complex operations to be composed from simple building blocks by operating on user-specified functions Many, many more features are contained in purrr beyond what was shown today Further reading Tidyverse website \u0026ldquo;Iteration\u0026rdquo; chapter in R for Data Science Hadley\u0026rsquo;s plyr package which handles array and data.frame inputs. Thank You! ","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"ada162679960820613751d888c288931","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/purrr/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/ComputingClub/workshops/purrr/","section":"workshops","summary":"Functional Programming in R with purrr","tags":null,"title":"Functional Programming in R with purrr","type":"docs"},{"authors":null,"categories":null,"content":"A collection of external resources classified by subjects (see menu on the left). Feel free to add any link to external resources here!\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1569369877,"objectID":"59c1a3532c7e6c5ec860704a6a171c03","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/ComputingClub/workshops/resources/","section":"workshops","summary":"A collection of external resources","tags":null,"title":"Resources","type":"docs"},{"authors":null,"categories":null,"content":"A collection of external resources classified by subjects (see menu on the left). Feel free to add any link to external resources here!\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1581973386,"objectID":"787af4087232dfb594a1976998019e23","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/tutorials/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/ComputingClub/workshops/tutorials/","section":"workshops","summary":"Articles written by our members","tags":null,"title":"Tutorials","type":"docs"},{"authors":null,"categories":null,"content":"General Many methods have an inplace argument which performs the operation inplace when set to True so that you do not need to overwrite the original DataFrame. It produces cleaner code as well as saves time and memory! Note that method chaining does not work with inplace=True since nothing is returned.\nRows and columns behave in the exact same way. Indeed, they are both implemented using pandas.Index or pandas.MultiIndex objects. The main difference is that columns can be indexed in an additional way since pandas.DataFrame objects can be access through the native python indexing, i.e., df[column]. Otherwise, most (all?) operations can be perform along any of the two axes. (If not, there is the .T or .transpose() methods to flip the DataFrame.)\nData Importation You probably all know about pandas.read_csv to load text files into pandas DataFrames. Here are some interesting options you might not know about:\nYou can overwrite the column names directly using names=[...] and header=0; You can set the index automatically using index_col=\u0026quot;column_name\u0026quot;; You can drop columns or rows before loading using usecols=[...] or skiprows=[...], respectively; If NAs are encoded in a particular way, you can specify it using na_values=[...]; encoding might be useful to fix some problems related to encoding; delim_whitespace can be useful when the separator is a variable number of whitespaces instead of a given character (,, \\t, etc.); Most of these operations can be done in separate steps after loading(for example, you could do a .replace(..., inplace=True) to change some values to NaN), but it might be better to do them in one step to improve legibility, speed and memory consumption.\nData Exportation You are probably aware of the .to_csv method to write a pandas DataFrame to a text file. Here are some interesting options:\nna_rep to encode NAs in a particular way; columns to only write specific columns; index, index_label and header to control the output. The .to_latex() method offers a convenient way to export a pandas DataFrame to LaTeX format. I have found that the column formatting does not work very well sometimes; you can perform the formatting by hand before using to_latex using commands such as:\ndf[\u0026#34;column\u0026#34;] = df[\u0026#34;column\u0026#34;].apply(\u0026#34;{:.2f}\u0026#34;.format) # float formatting df[\u0026#34;column\u0026#34;] = df[\u0026#34;column\u0026#34;].apply(\u0026#34;{:.2f} %\u0026#34;.format) # add a percentage sign df[\u0026#34;ci\u0026#34;] = df[[\u0026#34;lower\u0026#34;, \u0026#34;upper\u0026#34;]].apply(lambda x: \u0026#34;[{:.2f}, {:.2f}]\u0026#34;.format(x[\u0026#34;lower\u0026#34;], x[\u0026#34;upper\u0026#34;]), axis=0) # to converct CI bounds to an interval Accessing Values There are multiple ways to access the contents in a pandas DataFrame (most also work for Series as well).\nUsing python indexing (a DataFrame behaves as a dictionary of columns):\ndf[columns]: return all columns in columns; columns can be string (one column is returned) or a list of string. Using .loc:\ndf.loc[index_values]: returns the rows corresponding to index_values; index_values can be a single index value, a list of index values, a slice of values startrow:endrow or even a Boolean of the same length as df; df.loc[index_values, columns]: returns the specified columns of the specified rows; df.loc[:, columns]: does the same as df[columns]; df.loc[index_values, :]: does the same as df.loc[index_values]. Using .iloc:\ndf.iloc[index]: return the rows corresponding to index using integer indexing; index can be a single integer, a list of integers or even a range of integer startnum:endnum; df.iloc[row_index, col_index]: returns the specified rows and columns. Using .at to access a single value:\nsimilar indexing as .loc. Using .iat:\nsimilar indexing as .iloc. Using .query() can be used to select rows on some truth value defined by a string statement similar to that of SQL.\nHere are some interesting methods to create Boolean arrays to use in .loc[]:\n.isna(), .notna() checks whether values are NaN; .isin() corresponds to elementwise native in; .le, .lt, .ge, .gt, .eq and .ne are equivalent to \u0026lt;=, \u0026lt;, \u0026gt;=, \u0026gt;, == and !=, respectively; .between_time() when dealing with datetime format; Any Series methods: .between() is a nice shorthand for two comparisons; .str.\u0026lt;method\u0026gt; when dealing with strings .dt.\u0026lt;method\u0026gt; when dealing with datetime formats .cat.\u0026lt;method\u0026gt; when dealing with categorical values Setting Values To set values in a existing DataFrame, you can use all previous indexing methods:\nUse df[columns] or df.loc[:, columns] or df.iloc[:, columns] to set or add columns; Use df.loc[index] or df.loc[index, :] or df.iloc[index, :] to set or add rows; Use df.loc[index, columns] or df.iloc[index, columns] to set specific entries: same with .at and .iat to fill a specific cell. Note that new rows and columns might be added if index or columns contains values not in the current df. The .iloc and iat indexing generally does not support adding new rows and columns and raises an out-of-bound error when trying to set values outside the current df.\nFor any of these methods the syntax is through assignment where the right-hand side can be various things:\na list of list (e.g. a numpy array), a dict column: values, a single value copied for all cells, a pandas Series or Dataframe object, and many more combinations! To add new rows to a DataFrame, you can use one of the following:\ndf.loc[index] = row merging two DataFrames with same columns (see Merging DataFrames) To add new columns:\nUse df[columns] = values (multiple columns) Use df.insert(loc, column, values) (single column) merging two DataFrames with same indices (see Merging DataFrames) Other interesting methods:\nThe df.where() method can also be used to replace values where some condition is false; The df.mask() method is the converse to .where: it replaces values where the condition is true; The df.replace() replaces values; Using df.fillna() does what its name indicates; The df.update(other_df) can be useful in some cases (see Merging DataFrames for more details); The df.eval(str, inplace=True) method lets you compute a new column using a string description; Subsetting Data Subsetting data can be viewed in two ways: selecting rows/columns or dropping rows/data.\nTo select rows or columns, refer to Accessing data.\nTo drop rows or columns, you can:\nSelect your subset and overwrite the DataFrame as in df = df.loc[...]; Use the df.drop(..., inplace=True) method to drop rows or columns; The df.filter() method can select some rows/columns based on their content (like or a regex). Using df.take() performs similarly as .iloc[]; For more specific use cases:\nUse df.drop_duplicates(..., inplace=True) to drop repeated rows Use df.dropna(..., inplace=True) to drop rows or columns if they contain NaN values. Use df.truncate() when the condition is a range of indices. Reshaping DataFrames Transpose:\nThe method s .T and .transpose() do the same thing Wide to long format\nThe method df.melt(): take multiple columns into (column name, value); The method df.stack(): similar to melt, but less general; puts the original column names into a MultiIndex rather than new columns; The method df.explode(): when cells contains lists, this methods expand the dataframe for each element of the list. import pandas as pd df_wide = pd.DataFrame({\u0026#34;A\u0026#34;: range(5), \u0026#34;B\u0026#34;: range(5, 10), \u0026#34;C\u0026#34;: range(10, 15)}, index=list(\u0026#34;abcde\u0026#34;)) print(df_wide) A B C a 0 5 10 b 1 6 11 c 2 7 12 d 3 8 13 e 4 9 14 print(df_wide.melt(id_vars=\u0026#34;A\u0026#34;, value_vars=list(\u0026#34;BC\u0026#34;))) A variable value 0 0 B 5 1 1 B 6 2 2 B 7 3 3 B 8 4 4 B 9 5 0 C 10 6 1 C 11 7 2 C 12 8 3 C 13 9 4 C 14 print(df_wide.stack()) a A 0 B 5 C 10 b A 1 B 6 C 11 c A 2 B 7 C 12 d A 3 B 8 C 13 e A 4 B 9 C 14 dtype: int64 df_wide = pd.Series([range(3), range(1), range(10)]) print(df_wide) 0 (0, 1, 2) 1 (0) 2 (0, 1, 2, 3, 4, 5, 6, 7, 8, 9) dtype: object print(df_wide.explode()) 0 0 0 1 0 2 1 0 2 0 2 1 2 2 2 3 2 4 2 5 2 6 2 7 2 8 2 9 dtype: object Long to wide\nThe method df.pivot() creates columns based on unique levels of a given column filled with the corresponding values; The method df.pivot_table() generalizes .pivot to more complex situations where there may be duplicate entries which have to be aggregated. This is related to performing .groupby() chained with .agg(), but may have different output format; The method df.unstack() pivots a DataFrame using its index (useful for MultiIndex DataFrames mostly). df_long = pd.DataFrame({\u0026#34;id\u0026#34;: list(range(4))*3, \u0026#34;type\u0026#34;: [\u0026#34;A\u0026#34;]*4 + [\u0026#34;B\u0026#34;]*4 + [\u0026#34;C\u0026#34;]*4, \u0026#34;value\u0026#34;:range(12)}) print(df_long) id type value 0 0 A 0 1 1 A 1 2 2 A 2 3 3 A 3 4 0 B 4 5 1 B 5 6 2 B 6 7 3 B 7 8 0 C 8 9 1 C 9 10 2 C 10 11 3 C 11 print(df_long.pivot(index=\u0026#34;id\u0026#34;, columns=\u0026#34;type\u0026#34;, values=\u0026#34;value\u0026#34;)) type A B C id 0 0 4 8 1 1 5 9 2 2 6 10 3 3 7 11 print(df_long.pivot_table(index=\u0026#34;type\u0026#34;, aggfunc=\u0026#34;min\u0026#34;)) id value type A 0 0 B 0 4 C 0 8 # equivalent groupby+agg print(df_long.groupby(\u0026#34;type\u0026#34;).agg({\u0026#34;value\u0026#34;: \u0026#34;min\u0026#34;})) value type A 0 B 4 C 8 print(df_long.set_index([\u0026#34;type\u0026#34;, \u0026#34;id\u0026#34;])) value type id A 0 0 1 1 2 2 3 3 B 0 4 1 5 2 6 3 7 C 0 8 1 9 2 10 3 11 print(df_long.set_index([\u0026#34;type\u0026#34;, \u0026#34;id\u0026#34;]).unstack()) value id 0 1 2 3 type A 0 1 2 3 B 4 5 6 7 C 8 9 10 11 print(df_long.set_index([\u0026#34;id\u0026#34;, \u0026#34;type\u0026#34;]).unstack()) value type A B C id 0 0 4 8 1 1 5 9 2 2 6 10 3 3 7 11 Cross Tabulation\nThe pd.crosstab() function allows you to compute frequency tables along multiple groupings.\nMerging DataFrames Here are a few options on how to merge multiple DataFrames together. See Merge, join, and concatenate for more details.\nConcatenate\nThe function pd.concat([df1, df2]) lets you litteraly concatenate multiple DataFrames along some axis. This function works either as an inner join or an outer join on the multiple dataframes indices.\nThe function df.append(other_df) does concatenation on the index axis (i.e., add rows)\nUsing ignore_index=True can be useful when you don\u0026rsquo;t want to join on the indices and only really concatenate the dataframes. (This is most likely the way you want to use .append().)\nMerging\nThe function pd.merge lets you perform four types of joins: left, right, outer and inner which are closely related to their SQL equivalents. It generalizes pd.concat as you can use columns, instead of the index, to perform the join.\nThe inline version of pd.merge is to use the method .join on some pre-existing dataframe.\nThe method df.update(other) performs a left join by replacing the values of df using those in other. It replaces on non-NA values in the original df so this can be use to add values to a df; no new rows or columns can be created by .update.\nIterating through DataFrames If you need to traverse a DataFrame row by row, you can use:\n.iterrows() to return (index, row as Series); .itertuple() to return (index, named tuple); In both cases, you can use multiple assignment to catch each element.\nAnother, possibly better, way to do something to each row is through df.apply(fun). Thus, the manipulation you would do when iterating across rows could be wrapped into a function fun applied to each row. This also allows to apply a function by columns using axis=1. To apply a function to each cell, you can use .applymap(fun).\nfor i, (a, b, c, d) in df.iterrows(): print(a, b, c, d) for i, a, b, c, d in df.itertuples(): print(a, b, c, d) print(df.apply(sum, 1)) 0.0 0 20.0 30.0 1.0 1 21.0 31.0 2.0 2 22.0 32.0 3.0 3 23.0 33.0 100 4 102 103 100 5 nan nan 0.0 0 20.0 30.0 1.0 1 21.0 31.0 2.0 2 22.0 32.0 3.0 3 23.0 33.0 100 4 102 103 100 5 nan nan a 50.0 b 54.0 c 58.0 d 62.0 e 309.0 f NaN dtype: float64 Functions and Aggregation We have seen .apply and .applymap to apply a function row/column-wise or element-wise. The method .pipe allows you to chain and control multiple functions. Note that there exists many pre-defined functions which can be performed along axes by specifying axis=0/1/None for rows/columns/all.\nOften, functions applied to rows or columns are aggregation functions. The .agg, a.k.a. .aggregate, method lets you perform multiple aggregation functions and produce a well-formated output.\nThe .agg methods is particularly useful for grouped dataframes. The .groupby method splits a dataframe into many subsets defined by the arguments passed. Then, applying .agg to the grouped dataframe applies it to each subset and produces a dataframe where the index defines the subset and the columns define the aggregation functions.\nThe .describe function works as an .agg call acting on numerical columns only. This can be particularly useful when computing summary statistics on a dataset. Also, this can be chained with a groupby to perform description by subgroups of the data!\nMultiIndex DataFrames MultiIndex works just like regular indices except that they have a structure using levels: instead of a single key, each row has a tuple of values acting as a key. Playing with MultiIndex can be cumbersome sometimes so a nice trick to keep in mind is the .reset_index(inplace=True) method which moves the MultiIndex to new columns and creates a dummy index in its place.\nTransformations Using pandas\nTo encode categorical variables using integer indexing, you can use the function pd.factorize(array) or the method version series.factorize(). It returns the encoding as well as the encoded values. To get one-hot encoding, you can use pd.get_dummies().\nTo bin numerical variables, you can use pd.cut().\nUsing Scikit-learn\nIf you need to scale the data (say to mean 0 and variance 1), I suggest to use the StandardScaler from sklearn. It internally stores the mean and standard deviation used for standardization. Then, if you need to apply the same transformation to another matrix, you can do it easily. Also, if you need to recover the original matrix, you can!\nfrom sklearn.preprocessing import StandardScaler import numpy as np X = np.random.uniform(0, 1, (3, 4)) scaler = StandardScaler().fit(X) print(X) Xstd = scaler.transform(X) print(Xstd) print(scaler.inverse_transform(Xstd)) [[0.27355506 0.52822275 0.51469633 0.06545488] [0.44123359 0.69095683 0.52764392 0.44219493] [0.61651989 0.99101129 0.12910797 0.3453753 ]] [[-1.21558928 -1.0877613 0.6718045 -1.3702373 ] [-0.01811033 -0.23879521 0.74183104 0.98816536] [ 1.23369961 1.32655652 -1.41363554 0.38207193]] [[0.27355506 0.52822275 0.51469633 0.06545488] [0.44123359 0.69095683 0.52764392 0.44219493] [0.61651989 0.99101129 0.12910797 0.3453753 ]] Typically, categorical data is not encoded using integers. You can always produce a map to integer yourself but you need to keep track of the map. The LabelBinarizer can do that for you! Then, this uniformizes all encoding and ensures you can recover the correct original categories.\nfrom sklearn.preprocessing import LabelBinarizer y = np.array([\u0026#34;A\u0026#34;]*4 + [\u0026#34;B\u0026#34;]*6) print(y) label_encoder = LabelBinarizer(neg_label=0, pos_label=1) y_01 = label_encoder.fit_transform(y) print(y_01) print(label_encoder.inverse_transform(np.array([0, 1, 0, 1, 1, 0, 1]))) ['A' 'A' 'A' 'A' 'B' 'B' 'B' 'B' 'B' 'B'] [[0] [0] [0] [0] [1] [1] [1] [1] [1] [1]] ['A' 'B' 'A' 'B' 'B' 'A' 'B'] Some other interesting transformations (see Preprocessing and Normalization for many more):\nLabelEncoder for more than two categories (one-hot) MultiLabelBinarizer for multiple labels to 0/1 encoding ","date":1588114800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588628881,"objectID":"5524c60c10751731f0fd48a0b2ab2f5d","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/pandas/","publishdate":"2020-04-29T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/resources/pandas/","section":"workshops","summary":"General Many methods have an inplace argument which performs the operation inplace when set to True so that you do not need to overwrite the original DataFrame. It produces cleaner code as well as saves time and memory! Note that method chaining does not work with inplace=True since nothing is returned.\nRows and columns behave in the exact same way. Indeed, they are both implemented using pandas.Index or pandas.MultiIndex objects. The main difference is that columns can be indexed in an additional way since pandas.","tags":null,"title":"Data Manipulation using Python","type":"docs"},{"authors":null,"categories":null,"content":"General comments R equivalents\nglmnet: pyglmnet lme4: pymer4 and a sklearn wrapper sklearn-lmer Scikit-learn (sklearn)\nMostly produces predictive models (fit, predict and score); no built-in inference mechanisms Easy to perform CV for parameter selection (.GridSearchCV) Many metrics implemented Classification, Regression, Clustering, Distances and kernels Many preprocessing tools: Label encoding, scaling, standardization, transformations, etc. Many related packages: Related Projects SciKits Statsmodels (statsmodels)\nClassical statistical techniques with inference ANOVAs, LMM, GLM, hypothesis testing, etc. Regularization (Elastic net, Rigde, LASSO) Rich family of GLM distributions Uses R-like formulas to describe models Scipy stats module (scipy.stats)\nImplements some basic statistical functions: Distributions Estimators Hypothesis tests Transformations Gaussian KDE Categorical Data Logistic Regression\nsklearn.linear_model.LogisticRegression: L1, L2 and elastic net penalties For multi-class problems: one-vs-all and multinomial pyglmnet.GLM(distr=\u0026quot;binomial\u0026quot;) Elastic net regularization (LASSO and Ridge) Cross-validation Group regularization pymer4.Lmer(family=\u0026quot;binomial\u0026quot;) Mixed effect models pyGAM.LogisticGAM: GAM (with interactions), Cross-validation, similar to sklearn\u0026rsquo;s API statsmodels: Binomial GLM Binomial GLM GAM Binomial GLM LMM Multinomial GLM Other GLM\nProbit: pyglmnet.GLM(distr=\u0026quot;probit\u0026quot;) Elastic net regularization (LASSO and Ridge) Cross-validation Group regularization statsmodels: Probit GLM Ridge Classifier (Ridge regression on -1/+1 responses)\nsklearn.linear_model.RidgeClassifier sklearn.linear_model.RidgeClassifierCV performs CV on a solution path Discriminant analysis\nsklearn.discriminant_analysis LDA, QDA Ensemble and Tree-based Methods\nsklearn.ensemble: AdaBoost, Bagging, Gradient Boosting, Random Forest sklearn.trees.DecisionTreeClassifier Gaussian Process\nsklearn.gaussian_process.GaussianProcessClassifier Naive Bayes\nsklearn.naive_bayes K-Nearest-Neighbors\nsklearn.neighbors.KNearestNeighborsClassifier uniform weights, distance weights, custom weights multiple distance metrics Neural Networks\nsklearn.linear_model.Perceptron sklearn.neural_network.MLPClassifier multiple layers activations: identity, logistic (sigmoid), ReLU, tanh weight decay sklearn.neural_network.BernoulliRBM sknn.nlp.Classifier Compatible with sklearn Many more types of layers and activations pyTorch, TensorFlow (see also Keras) Support Vector Machines\nsklearn.svm Linear Kernel: linear, polynomial, Gaussian, etc. Multiclass and Multilabel Data\nsklearn.multiclass meta-estimator for one-vs-one and one-vs-rest (one-vs-all) sklearn.multioutput.MultiOutputClassifier to apply binary classifiers to multiple outputs Numerical Data Linear Regression, ANOVA and Linear Mixed Models\nsklearn.linear_model.LinearRegression Regularizations: Ridge, LASSO, Elastic net Multi-task/multi-output: Elastic net, LASSO pymer4 Mixed effect models sklearn-lmer: a sklearn wrapper with CV pyglmnet.GLM(distr=\u0026quot;gaussian\u0026quot;) Elastic net regularization (LASSO and Ridge) Cross-validation Group regularization pyGAM.LinearGAM: GAM (with interactions), Cross-validation, similar to sklearn\u0026rsquo;s API statsmodels Linear Regression GAM Linear Mixed Effect Models ANOVA MANOVA GLM\nCount data (Poisson) pyglmnet.GLM(distr=\u0026quot;poisson\u0026quot;) Elastic net regularization (LASSO and Ridge) Cross-validation Group regularization pymer4.Lmer(family=\u0026quot;poisson\u0026quot;) Mixed effect models pyGAM.PoissonGAM: GAM (with interactions), Cross-validation, similar to sklearn\u0026rsquo;s API statsmodels: Contingency Tables Poisson GLM Poisson GLM GAM Poisson GLM LMM Generalized Poisson GLM Count data (Binomial) statsmodels: Binomial GLM Binomial GLM GAM Binomial GLM LMM Count data (Negative Binomial) statsmodels: Negative Binomial GLM Poisson GLM GAM Count data (Zero-Inflated Models) statsmodels: Zero-Inflated Poisson GLM Zero-Inflated NegativeBinomial GLM Zero-Inflated Generalized Poisson GLM Right-continuous Data (Gamma) pyglmnet.GLM(distr=\u0026quot;gamma\u0026quot;) Elastic net regularization (LASSO and Ridge) Cross-validation Group regularization pymer4.Lmer(family=\u0026quot;gamma\u0026quot;) Mixed effect models pyGAM.GammaGAM: GAM (with interactions), Cross-validation, similar to sklearn\u0026rsquo;s API statsmodels: Gamma GLM Gamma GLM GAM Right-continuous Data (Inverse Gaussian) pymer4.Lmer(family=\u0026quot;inverse_gaussian\u0026quot;) Mixed effect models pyGAM.InvGaussGAM: GAM (with interactions), Cross-validation, similar to sklearn\u0026rsquo;s API statsmodels: Inverse Gaussian GLM Inverse Gaussian GLM GAM Right-continuous with Excess Zero Data (Tweedie with $p\\in(1,2)$) statsmodels: Tweedie GLM Tweedie GLM GAM Kernel Linear Regression\nsklearn.kernel_ridge.KernelRidge Kernels: linear, polynomial, Gaussian, etc. Ensemble and Tree-based Methods\nsklearn.ensemble: AdaBoost, Bagging, Gradient Boosting, Random Forest sklearn.trees.DecisionTreeRegressor Gaussian Process\nsklearn.gaussian_process.GaussianProcessRegressor K-Nearest-Neighbors\nsklearn.neighbors.KNearestNeighborsRegressor uniform weights, distance weights, custom weights multiple distance metrics Neural Networks\nsklearn.neural_network.MLPRegressor multiple layers activations: identity, logistic (sigmoid), ReLU, tanh weight decay sknn.nlp.Regressor Compatible with sklearn Many more types of layers and activations pyTorch, TensorFlow (see also Keras) Support Vector Machines\nsklearn.svm Linear Kernel: linear, polynomial, Gaussian, etc. Unsupervised Learning Clustering\nsklearn.cluster K-means, Agglomerative clustering Gaussian Mixture Model\nsklearn.mixture.GaussianMixture Dimensionality Reduction sklearn.decomposition: Kernel PCA, PCA sklearn.manifold: Isomap, t-SNE, eetc. sknn.ae.AutoEncoder Neural network autoencoder ","date":1588114800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588628881,"objectID":"c5a039c3091afcd87eeb7a1414f55413","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/python_models/","publishdate":"2020-04-29T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/resources/python_models/","section":"workshops","summary":"General comments R equivalents\nglmnet: pyglmnet lme4: pymer4 and a sklearn wrapper sklearn-lmer Scikit-learn (sklearn)\nMostly produces predictive models (fit, predict and score); no built-in inference mechanisms Easy to perform CV for parameter selection (.GridSearchCV) Many metrics implemented Classification, Regression, Clustering, Distances and kernels Many preprocessing tools: Label encoding, scaling, standardization, transformations, etc. Many related packages: Related Projects SciKits Statsmodels (statsmodels)\nClassical statistical techniques with inference ANOVAs, LMM, GLM, hypothesis testing, etc.","tags":null,"title":"Modeling using Python","type":"docs"},{"authors":null,"categories":null,"content":"Overview of the Academic theme layouts The content of this website rely on two different type defined by the Academic theme. Each .Md must specify, in its header, what type it is based on in order for Hugo to produce the correct html page.\npage (for meetings and post) Single page output; The page contains a header block describing the post/meeting and that information is taken from the Markdown header; Followed by a body for regular Markdown for the post or if you want to add more details to a meeting. docs (for workshops and resources) Each docs file is associated with a single html page, but multiple docs can be associted together within a folder to form different pages of a single workshop; Consists of a simple Markdown body; A within-workshop table of content is added to the left; A within-pasge table of content on the right. Create your author profile First things first, you need to create an authors profile in order to associate multiple content to the same author. Unfortunately, Hugo does not provide a command to create a new author from command line, so the fastest way to go is to copy the blank author folder and give it a name representing your\u0026rsquo;s (say username from now on). Then, edit the _index.md contained in the new username folder and edit its content. It should be documented well enough for you to complete.\nIf you want to add a picture of yourself, place it in the username folder with the name avatar.jpg/.png.\nCreate a meeting Create a workshop Add resources Create a post ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570245843,"objectID":"16bd0e28decebba9cc098f9d6c708848","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/edit_site/createcontent/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/edit_site/createcontent/","section":"workshops","summary":"Overview of the Academic theme layouts The content of this website rely on two different type defined by the Academic theme. Each .Md must specify, in its header, what type it is based on in order for Hugo to produce the correct html page.\npage (for meetings and post) Single page output; The page contains a header block describing the post/meeting and that information is taken from the Markdown header; Followed by a body for regular Markdown for the post or if you want to add more details to a meeting.","tags":null,"title":"Creating content","type":"docs"},{"authors":null,"categories":null,"content":"Language, packages Conda integration in GreatLakes by UMich Data Analysis Networking Group\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569369877,"objectID":"e8915e1808b0a1f9da4026c862ff0a3e","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/hpc/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/resources/hpc/","section":"workshops","summary":"Language, packages Conda integration in GreatLakes by UMich Data Analysis Networking Group","tags":null,"title":"High Performance Computing","type":"docs"},{"authors":null,"categories":null,"content":"Editors LyX, a WYSIWYG LaTeX editor useful for quick math writing. Citation management Zotero for local and remote bibliography management.\nZotero connector for Zotero integration in browsers.\nbibtex vs biblatex vs biber vs natbib to understand the differences.\nMRLookup has a nice search engine to get verified citations for many peer-reviewed publications. You can get BibTeX formatted exports. Many journals require the MR number, so you can find them using that tool. Also, check out Abbreviations of Names of Serials if you want the abbreviated version of journal names.\nEditing equations Use the \\left and \\right commands near brackets and parens to automatically size them (i.e. outer brackets will be made larger than inner brackets). The align environment will add a tag to each line as a separate equation. Using split within an equation or align will assign one label to all lines. You can use the \\tag command to edit the number next to an equation \\tag{Hi Rob} will change an equation label from \u0026ldquo;(1)\u0026rdquo; to \u0026ldquo;(Hi Rob)\u0026rdquo; This can be a useful, if somewhat hacky, way to add commentary to multiline equations The \\label command assigns an internal keyword which is used in referencing via \\ref or \\cref, whereas \\tag will change the actual label that appears in the output. Referencing equations/figures The \\Cref command will automatically determine what is being referenced based on the type of the object that was labelled. For example, \\ref{mylabel} will display as \u0026ldquo;Equation (1)\u0026rdquo; if \\label{mylabel} is next an equation and \u0026ldquo;Figure (1)\u0026rdquo; if \\label{mylabel} is close to a figure. \\autoref does something similar, but depends on a specific convention within the label. For example, you need to prepend an eq: so \\autoref{eq:mylabel} will show up as \u0026ldquo;Equation (1)\u0026rdquo;. Some tips and tricks Check out Detexify to find the correct math symbol by drawing it.\nCheck out the todonotes package to add todo notes and comments to LaTeX files and pdf output.\nUse include or input to insert the content of another .tex file where you want it. For example, you can maintain a math macro file that you use often or organize your sections/chapters in different files. Also, read When should I use \\input vs. \\include?.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582041411,"objectID":"ae92ee363cb60417e54317622810a6e0","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/latex/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/resources/latex/","section":"workshops","summary":"Editors LyX, a WYSIWYG LaTeX editor useful for quick math writing. Citation management Zotero for local and remote bibliography management.\nZotero connector for Zotero integration in browsers.\nbibtex vs biblatex vs biber vs natbib to understand the differences.\nMRLookup has a nice search engine to get verified citations for many peer-reviewed publications. You can get BibTeX formatted exports. Many journals require the MR number, so you can find them using that tool.","tags":null,"title":"LaTeX","type":"docs"},{"authors":null,"categories":null,"content":"Package and application manager (Homebrew) Installation: follow the instructions on the website Basic commands: brew install \u0026lt;package\u0026gt; to install a particular package; brew cask install \u0026lt;application\u0026gt; to install an application (will appear in the Applications folder); brew search \u0026lt;name\u0026gt; to list available formulae containing name; Useful to export some (all) packages to another environment (brew bundle command) resolving all dependencies. Terminal customization Oh My ZSH! Cool Apps Magnet window manager (App Store) ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582064264,"objectID":"ff995267abc9496acd53906263ab1a8a","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/macos/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/resources/macos/","section":"workshops","summary":"Package and application manager (Homebrew) Installation: follow the instructions on the website Basic commands: brew install \u0026lt;package\u0026gt; to install a particular package; brew cask install \u0026lt;application\u0026gt; to install an application (will appear in the Applications folder); brew search \u0026lt;name\u0026gt; to list available formulae containing name; Useful to export some (all) packages to another environment (brew bundle command) resolving all dependencies. Terminal customization Oh My ZSH! Cool Apps Magnet window manager (App Store) ","tags":null,"title":"MacOS","type":"docs"},{"authors":null,"categories":null,"content":"Smoke Testing Wikipedia\nSmoke testing is a quick and easy way to check if code works. If your program can\u0026rsquo;t even run without crashing, there\u0026rsquo;s no point to performing more fine-grained testing procedures.\nsqrt_1 \u0026lt;- function(x) { if (x \u0026gt;= 0) { ret \u0026lt;- x^(0.5) } else { ret \u0026lt;- (-x)^(0.5) + \u0026#34;i\u0026#34; } return(ret) } sqrt_2 \u0026lt;- function(x) { if (x \u0026gt;= 0) { ret \u0026lt;- x^(0.5) } else { ret \u0026lt;- paste0((-x)^(0.5), \u0026#34;i\u0026#34;) } return(ret) } Here is the smoke-test we might right. Notice that the output is not checked; we just want to check if there are any errors.\nsmoke_test \u0026lt;- function(test_input) { sqrt_1(test_input) # will raise an error sqrt_2(test_input) # will not raise an error, but is problematic } smoke_test(2) smoke_test(3.14) smoke_test(-2) The Unit Testing paradigm Test-driven development\nOptimal workflow with an example We want to implement a square root function with the following behaviour:\nreturns the square root for positive input returns the complex square root for negative input is vectorized and return vectors/matrices with the same dimension if one input is negative, all outputs are in complex form raises an appropriate error if the input is not numeric (or any element of the input is not numeric) Before writing the function, we could write the following tests:\nsqrt(1) = 1 sqrt(-1) = 0+1i (depends on how complex numbers are implemented) sqrt([0, 1]) = [0, 1] sqrt([[0], [-1]]) = [[0+0i], [0+1i]] sqrt(\u0026quot;a\u0026quot;) raises an error sqrt([0, \u0026quot;A\u0026quot;]) raises an error Then, we implement our function checking tests constantly until all criterions are satisfied.\nSome (most) IDEs can automatically run all your tests in the background when any file is saved: this checks the current function your are implementing and also that you did not break any prior developments. This constant checking enable you to quickly diagnose the problem as only your latest edits change the result of tests.\nAnother approach In practice, before writing a specific function, we might not know exactly what it\u0026rsquo;s behaviour will be so it is not clear what tests to write beforehand. (I often get excited about implementing something and writing tests is boring\u0026hellip;)\nSo, instead of writing the tests before the function, we can wait until we are satisfied with the behaviour of a function and protect it with tests. Then, interactions with future functions will have some safeguards against bad input or output. Also, any further changes you perform on the function will have to satisfy the tests you previously wrote so any functions depending on the current function should not break.\nFurthermore, the creation of tests after the function may tell you that you have to refactor some parts of your function. When first writing it, you might not have thought of some edge case and the time spent wirting tests may uncover those cases.\nWhat to test Known output (e.g., simple cases you can compute by hand) In/out typing (behaviour under bad input, correct output given input) Output dimensions (column vs row vector, do you drop a dimension if it has length 1, etc.) Expected errors Some notes Unit testing is great for interactive languages to detect if you are inadvertantly using global variables (defined outside the scope of a function). The test suite runs outside your scripts so tests will fail if you do so. Unit Testing in R using the testthat package Let\u0026rsquo;s create a simple R package in RStudio:\nNew Project R Package New Project Put in some name Check Open in new session Let\u0026rsquo;s add the above defined functions in the hello.R file.\nLet\u0026rsquo;s create some tests:\nRun devtools::test() and type in 1 to create the tests directory, which contains a testthat.R file managing imports and helps in running all tests at once, and a sub-directory testthat where we will add some test; Run test using Build \u0026gt; Test Package or simply type Ctrl+Shift+T or run devtools::test(). You should see an output saying there are no tests in the testthat directory (as expected). Create a test_sqrt_1.R file in tests/testthat (NB: all test file must start with test so it can be discovered by the testthat package.) At the head of the file, add `context(\u0026ldquo;Test sqrt functions\u0026rdquo;) which will yield a more verbose output. Add a first test (note the near-grammarly syntax: the first argument is what we are testing that sqrt_1() works on positive input): test_that( \u0026#34;sqrt_1() works on positive input\u0026#34;, # what we are testing { # the test itself, using expect statements expect_equal(sqrt_1(1.0), 1.0) expect_equal(sqrt_1(0.0), 0.0) } ) Run tests again and observe that our function passes all tests so far. Let\u0026rsquo;s add another succeding test, but on an expected non-successfull call: test_that( \u0026#34;sqrt_1 raises an error with negative inputs\u0026#34;, { expect_error(sqrt_1(-1.0), \u0026#34;non-numeric argument\u0026#34;) } ) Running all tests should again suceed. Now, let\u0026rsquo;s add a test which fails: test_that( \u0026#34;sqrt_1 returns imaginary numbers for negative inputs\u0026#34;, { expect_match(sqrt(-1.0), \u0026#34;1i\u0026#34;) } ) Unit Testing in Python using the unittests package unittest documentation\nCreate a simple module:\nTestModule/ sqrt.py test/ test_sqrt.py where\n# sqrt.py import math def sqrt(x): return math.sqrt(x) # test_sqrt.py import unittest import sqrt class MyTestCase(unittest.TestCase): def test_something(self): self.assertEqual( sqrt.sqrt(1.0), 1.0, \u0026#34;what happened if the test failed\u0026#34; ) if __name__ == \u0026#39;__main__\u0026#39;: unittest.main() Run tests using\npython -m unittest tests/test_sqrt.py python -m unittest discover tests The discover tests implies that the unittest package will search the tests directory for all tests in there.\nThe basic unittest package is not well suited to check equality of numpy arrays. Here\u0026rsquo;s a way to do it:\nimport numpy as np class MyTest(unittest.TestCase): def numpy_test_case(self): try: np.testing.asser_array_almost_equal( array1, array2 ) result = True except AssertionError as error: result = False self.assertTrue(res, \u0026#34;what happened if the test failed\u0026#34;) In PyCharm, you can set up automatic testing as follows:\nFile \u0026gt; Settings \u0026gt; Tools \u0026gt; Python Integrated Tools Select Unittests under Testing In the Project pane (the directory), left click on the tests directory and select Craete unittest in tests and click OK Run tests once Run \u0026gt; Run Unittests in tests In the Run pane, click on Toggle auto-test Now, any changes to files automatically triggers all tests to be run! Unit Testing in Julia This guide gives a nice, detailed walkthrough on how to set up a package in Julia with tests and integrate it with Travis and Codecov.\nJulia comes with the \u0026lsquo;Test\u0026rsquo; module built-in which offers basic unit tests.\nsqrt_im(x::Real) = sqrt(complex(x)) using Test # Unit tests (check for right value in both cases) @test sqrt_im(2.0) ≈ 1.4142135623730951 @test sqrt_im(5.0) ≈ 1.4142135623730951 @test sqrt_im(-2.0) ≈ 1.4142135623730951im # Random input using Random Z = randn(MersenneTwister(555), 10) @test (sqrt_im.(Z)).^2 ≈ Z @test sqrt(2.0) ≈ 1.4142135623730951 @test sqrt(-2.0) ≈ 1.414213562373095im # \u0026#34;test_broken\u0026#34; lets us mark tests we know give the wrong answer or raise an error @test_broken sqrt(-2.0) ≈ 1.414213562373095im # \u0026#34;test_broken\u0026#34; will return an Error testing value if the expression passes @test_broken sqrt(2.0) ≈ 1.4142135623730951 # Julia requires a boolean result to pass; for smoke testing this can be alleviated # by just always returning true @test begin sqrt_im(-2.0) true end @test begin sqrt(-2.0) true end Resources ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583856283,"objectID":"b3979dfeda91735da27b80f7d9129a93","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/packages/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/resources/packages/","section":"workshops","summary":"Smoke Testing Wikipedia\nSmoke testing is a quick and easy way to check if code works. If your program can\u0026rsquo;t even run without crashing, there\u0026rsquo;s no point to performing more fine-grained testing procedures.\nsqrt_1 \u0026lt;- function(x) { if (x \u0026gt;= 0) { ret \u0026lt;- x^(0.5) } else { ret \u0026lt;- (-x)^(0.5) + \u0026#34;i\u0026#34; } return(ret) } sqrt_2 \u0026lt;- function(x) { if (x \u0026gt;= 0) { ret \u0026lt;- x^(0.5) } else { ret \u0026lt;- paste0((-x)^(0.","tags":null,"title":"Package Development","type":"docs"},{"authors":null,"categories":null,"content":"Git The Pro Git book by Scott Chacon and Ben Straub:\n10. Git Internals: a deep understanding of git. Oh Shit, Git!?! and Dangit, git!: two go-to resources when encountering git problems.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570078435,"objectID":"9a5b4dfe316baa094a4582b0049b4a4c","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/versioncontrol/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/resources/versioncontrol/","section":"workshops","summary":"Git The Pro Git book by Scott Chacon and Ben Straub:\n10. Git Internals: a deep understanding of git. Oh Shit, Git!?! and Dangit, git!: two go-to resources when encountering git problems.","tags":null,"title":"Version Control","type":"docs"},{"authors":null,"categories":null,"content":"The lazy way If you only need to add some post/meeting/workshop to the website, here is a simple way to deploy your new content to the website without much hassle.\nCreate your content\u0026mdash;The first step is to create your specific content by producing the necessary Markdown files. See Creating content for details on how to do so. Push your content\u0026mdash;You then need to add your content to the website content directory. If you have access to the UMichStatistics repository, then you can do it directly using your favorite \u0026lsquo;git\u0026rsquo; workflow. Otherwise, contact the maintainers for them to add your content to the site. Deploy your content\u0026mdash;As mentionned, an update of the files outside the docs folder will not affect the public website. The deployment must be done through Hugo and, for now, this must be done manually. Contact the maintainers for it to happen. The good way Hopefully, you will want to deploy your changes yourself. To do this, here is the summary of the procedure:\nHave a local copy of the website on your machine. Update your local version. Deploy your local version to your localhost using Hugo in order to update the docs contents. Push your changes, including both the source and the updated docs to the site\u0026rsquo;s repository. With the workflow, your changes will instantaneously update the public website. Also, since you first deploy on your local machine, you are able to see the results of your changes before them becoming public. Finally, pushing both the source and the updated docs prevents conflicts in future updates.\nRequirements To use this process, you will need:\nAccess to the organization repository; git installed on your machine (see this guide); Basic git knowledge (clone, pull, add, commit and push). Note that most modern IDEs offer git support so you may execute all those steps using your interface; Hugo installed on your machine (see this guide. The installation on Windows is tedious and the only way I could make it work was R \u0026gt; install package blogdown \u0026gt; blogdown::install_hugo() and manually add its path to the system environment variables.) Update the local version First, you will need the latest version of the website stored locally on your machine.\nIf you have not cloned the repository yet, do so:\ngit clone https://github.com/UMichStatistics/ComputingClub.git \u0026lt;new-folder-name\u0026gt; The website relies on the Academic theme for Hugo, so you will to clone that as well. Fortunately, it is included as a submodule of the repository, so you only need to update all submodules (there is only one):\ngit submodule update [--init] [--recursive] If you already have cloned the repository, make sure your local version is up to date with the current online version to avoid merge conflicts when pushing. In a command prompt, move to the site local folder and pull the website (or fetch and merge).\nCreate your content Create your specific content by producing the necessary Markdown files and place them in the correct folders. See Creating content for details on how to do so.\nDeploy your local website Now that your local repository contains updated content, it is time to deploy it to your local docs folder. To do so, open a command prompt and run hugo at the root of the site\u0026rsquo;s local repository and type in:\nhugo which will compile the content into the static html pages. Unless your code does not compile, you should get an output such as (possibly containing warnings)\nBuilding sites … WARN 2019/09/24 17:08:23 In the next Hugo version (0.58.0) we will change how $home.Pages behaves. If you want to list all regular pages, replace .Pages or .Data.Pages with .Site.RegularPages in your home page template. | EN +------------------|----+ Pages | 52 Paginator pages | 0 Non-page files | 6 Static files | 8 Processed images | 9 Aliases | 7 Sitemaps | 1 Cleaned | 0 Total in 265 ms This means that Hugo has successfuly deployed your site to the docs folder. If you wish to view the website, you can host it locally using Hugo:\nhugo server which should yield something like\nWatching for changes in /home/simon/git/ComputingClub/{content,data,static,themes} Watching for config changes in /home/simon/git/ComputingClub/config.toml, /home/simon/git/ComputingClub/config/_default Environment: \u0026#34;development\u0026#34; Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ComputingClub/ (bind address 127.0.0.1) Press Ctrl+C to stop The url http://localhost:1313/ComputingClub/ is where you find your local website (use the one in your output as it may differ from mine). Also, as long a you do not close the server (by closing the command prompt or by typing Ctrl+C), Hugo will listen to any changes, meaning that any file saved in the root repository will trigger deployment. This is useful if you want to create your content and see it deployed instantaneously locally without calling Hugo each time. Note that creating new pages or making large changes may not appear in this \u0026ldquo;Fast Render Mode\u0026rdquo;, so you may need to exit and re-host.\nPush your changes Once your are satisfied with your local version, you need to push your changes to the master branch. In the case your Hugo server is still on, close it and run hugo one last time to redo the docs file for the online version, not the local version.\nStage and commit your changes:\ngit add --all git commit -m \u0026#39;some description of your changes\u0026#39; and finally push to the online repository\ngit push ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570209932,"objectID":"24c3d9913df929129210ecc33f7ffcce","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/edit_site/workflow/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/edit_site/workflow/","section":"workshops","summary":"The lazy way If you only need to add some post/meeting/workshop to the website, here is a simple way to deploy your new content to the website without much hassle.\nCreate your content\u0026mdash;The first step is to create your specific content by producing the necessary Markdown files. See Creating content for details on how to do so. Push your content\u0026mdash;You then need to add your content to the website content directory.","tags":null,"title":"Update workflow","type":"docs"},{"authors":null,"categories":null,"content":"Cheat sheets A very handy ggplot cheat sheet containing most functionalities and their syntax! (Suggested by Vincenzo Loffredo)\nA bunch of very useful R and RStudio cheat sheets. (Suggested by Drew Yarger)\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582042358,"objectID":"98fcf31c38ad5567019dcbbbb1b51849","permalink":"https://umichstatistics.github.io/ComputingClub/workshops/resources/r/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/ComputingClub/workshops/resources/r/","section":"workshops","summary":"Cheat sheets A very handy ggplot cheat sheet containing most functionalities and their syntax! (Suggested by Vincenzo Loffredo)\nA bunch of very useful R and RStudio cheat sheets. (Suggested by Drew Yarger)","tags":null,"title":"All things R","type":"docs"},{"authors":["Simon Fontaine"],"categories":null,"content":"","date":1675098000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"6e3e344dc51b6e837653d7472859606b","permalink":"https://umichstatistics.github.io/ComputingClub/talk/experiment/","publishdate":"2023-01-24T12:00:00-05:00","relpermalink":"/ComputingClub/talk/experiment/","section":"talk","summary":"Statistics research often requires some embarrassingly parallel computations: you might want to apply your method to a sequence of synthetic data sets, apply multiple variants of your method to the same data set, compare your method to existing methods, and any combination thereof. All of these cases involve executing very similar code with just a few changes between runs. While you can manage all these parallel experiments on your own, significant development time can be saved and many headaches can be avoided by using parameter exploration tools. In this meeting, we will be discussing two such tools: `batchtools` in R and `pypet` in Python. If time allows, we will also be looking at the interaction of those tools with the Great Lakes cluster through the Slurm scheduler.","tags":["R","Python"],"title":"Experiment Management with batchtools (R) and pypet (Python)","type":"talk"},{"authors":["Simon Fontaine"],"categories":[],"content":"The Computing Club is proud to announce its expansion to the Biostatistcs department! The Club will now hold joint meetings with PhD students from both the Statistics \u0026amp; Biostatistics department. With this change, we hope to draw even more students to share their computing knowledge. We would like to use this opportunity to welcome Ben Brennan, who will join the organizing committee!\nThe Club meetings will start back with the 2023 Winter semester. Until then, we invite you to join the Mcommunity which will automatically add you the our new Slack workspace. This new workspace is primarily a platform for students to ask for computing help and share things with each other.\nWe will soon send an invitation to present to gather a list of potential presenters and topics!\n","date":1666706776,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667167623,"objectID":"9b92e63adc23c20feb24532826a20d89","permalink":"https://umichstatistics.github.io/ComputingClub/post/2023/","publishdate":"2022-10-25T10:06:16-04:00","relpermalink":"/ComputingClub/post/2023/","section":"post","summary":"The Computing Club is proud to announce its expansion to the Biostatistcs department! The Club will now hold joint meetings with PhD students from both the Statistics \u0026amp; Biostatistics department. With this change, we hope to draw even more students to share their computing knowledge. We would like to use this opportunity to welcome Ben Brennan, who will join the organizing committee!\nThe Club meetings will start back with the 2023 Winter semester.","tags":["Club"],"title":"Biostatistics Expansion \u0026 Slack Workspace","type":"post"},{"authors":["Statistics Computing Club"],"categories":null,"content":"","date":1616079600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"3ee263e32b34801efe26147c22e46f58","permalink":"https://umichstatistics.github.io/ComputingClub/talk/github/","publishdate":"2021-03-11T14:00:00-05:00","relpermalink":"/ComputingClub/talk/github/","section":"talk","summary":"This week's seminar is hosted by the UM Statistics Computing Club. Join for an informal discussion of GitHub and some its more advanced features, including how one can use [GitHub Actions](https://github.com/features/actions) to automate various workflows (e.g., building hugo-powered websites from source, running unit tests on pull requests, etc). Some members will briefly demonstrate how they use actions and other features of GitHub.\nThis event will be structured primarily as a discussion with brief ad-hoc demos. Anyone from a beginner to expert is welcome, but we expect that those in attendance will participate, ask questions, and share their knowledge. ","tags":[],"title":"A Discussion of Advanced GitHub Usage, Including Actions","type":"talk"},{"authors":["Simon Fontaine"],"categories":null,"content":"","date":1606912200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"e961a22553ef6c8f9d021844ea0158a6","permalink":"https://umichstatistics.github.io/ComputingClub/talk/fastr/","publishdate":"2020-10-01T15:16:15-04:00","relpermalink":"/ComputingClub/talk/fastr/","section":"talk","summary":"R is a great language for statisticians because of its interactivity, simple syntax and access to multiple libraries produced by the community. These features also allow rapid prototyping, testing and debugging of new methods; however, the short implementation time is often outweighed by long execution times. To produce more efficient code and libraries, R possess simple interfaces to other languages such as C++ and Fortran, enabling efficient runtime with limited additional implementation. Indeed, executing the core calculations of a method in a compiled language can produce speed-ups in the order of 10-100x and up to 1000x in some cases. We will consider a few examples to showcase the increase in efficiency of compiled code compared to interpreted R code and build a simple R package from scratch to exhibit the simplicity of the process.\nThe second part of the presentation will be of the workshop type: if you wish to follow along, you will need to have the R packages “Rcpp” and “devtools” installed. ","tags":[],"title":"Speeding up R with C/C++/Fortran","type":"talk"},{"authors":["Dan Kessler"],"categories":null,"content":"","date":1602160200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"c2d4546f9d141b2736683c02162de6a5","permalink":"https://umichstatistics.github.io/ComputingClub/talk/git_seminar/","publishdate":"2020-10-01T15:16:15-04:00","relpermalink":"/ComputingClub/talk/git_seminar/","section":"talk","summary":"Whether you're analyzing data, developing an R package, or even writing your dissertation, chances are you're editing text files. Effective version control of these files can provide protection against data loss and mistakes, improve your efficiency, help you isolate bugs, and facilitate collaboration with others. Git is a leading tool for version control, but many statisticians have at best a shallow understanding of how it works. In this talk, I'll present Git in a way that you may not have seen before. Rather than giving you a cookbook of steps to memorize, I'll be explicating some of its underlying architecture. This will help you to understand how to use git effectively in a variety of situations. This presentation is designed to be very \"hands on\" and frequent questions from the audience are encouraged. Please ensure that you have git installed on our computer so that you can follow along.","tags":[],"title":"Git's a Wonderful Life","type":"talk"},{"authors":["Statistics Computing Club"],"categories":null,"content":"","date":1583863200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"ca0f6a53c937fc643af69caab0035306","permalink":"https://umichstatistics.github.io/ComputingClub/talk/packages/","publishdate":"2019-09-25T15:16:15-04:00","relpermalink":"/ComputingClub/talk/packages/","section":"talk","summary":"This meeting is focused on package development, with a particular emphasis on writing tests to ensure code is error-free. The discussion includes many examples from R, but other languages are welcome as well.\nLinks, resources and topics will be listed in [Resources/Packages](../../workshops/resources/packages). ","tags":[],"title":"Package development and testing in R","type":"talk"},{"authors":["Statistics Computing Club"],"categories":null,"content":"","date":1582048800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"71ccc98072a0d63deb37e70065eddd15","permalink":"https://umichstatistics.github.io/ComputingClub/talk/macos/","publishdate":"2019-09-25T15:16:15-04:00","relpermalink":"/ComputingClub/talk/macos/","section":"talk","summary":"This meetings is focused on statistical computing on MacOS. Potential topics include setting up Homebrew, LaTeX, R, the terminal, and other essential components in a statistician's workflow.\nLinks, resources and topics will be listed in [Resources/MacOS](../../workshops/resources/macos). ","tags":[],"title":"Statistical Computing in MacOS","type":"talk"},{"authors":["Statistics Computing Club"],"categories":null,"content":"","date":1580839200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"58414eae75f47db45042efaa5c41b103","permalink":"https://umichstatistics.github.io/ComputingClub/talk/latex/","publishdate":"2020-02-04T10:15:15-05:00","relpermalink":"/ComputingClub/talk/latex/","section":"talk","summary":"The topic of the first meeting will be a collaborative discussion about LaTeX, so we encourage you to come and share any interesting tips and tricks you’ve picked up. On the other side, if you are unsure of the “best way” to do something in LaTeX, we encourage you to bring it up for discussion.\nLinks, resources and topics will be listed in [Resources/LaTeX](../../workshops/resources/latex)","tags":[],"title":"LaTeX discussion","type":"talk"},{"authors":["Rob Trangucci"],"categories":null,"content":"","date":1574267400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"32af726d9106f79e8394f9139efee55c","permalink":"https://umichstatistics.github.io/ComputingClub/talk/stan/","publishdate":"2019-09-25T15:16:15-04:00","relpermalink":"/ComputingClub/talk/stan/","section":"talk","summary":"''Stan is a state-of-the-art platform for statistical modeling and high-performance statistical computation. Thousands of users rely on Stan for statistical modeling, data analysis, and prediction in the social, biological, and physical sciences, engineering, and business.''---[Stan website](https://mc-stan.org/)","tags":[],"title":"Stan","type":"talk"},{"authors":["Statistics Computing Club"],"categories":null,"content":"","date":1573754400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"d8253556c3675173c9ae37368f77173e","permalink":"https://umichstatistics.github.io/ComputingClub/talk/hpc/","publishdate":"2019-09-25T15:16:15-04:00","relpermalink":"/ComputingClub/talk/hpc/","section":"talk","summary":"Effective computing is a key component of many statistics workflows. The statistics department offers its graduate students access to a UMich HPC (high performance computing) resource. However, that resource will be changing as Flux retires at the end of November and we transition to Great Lakes. One important change is that rather than having access to a fixed number of resources at any given time, billing will be based on actual usage, so without new policies it may be possible for one user to (accidentally) burn through an entire month’s budget in a single day. Efficient use of this resource will be even more important and will require navigating the job submission system (SLURM), writing code in a way which can be parallelized effectively across multiple machines, and understanding how jobs are billed to the Statistics department account.\nThis special student seminar will have two parts, focused on the new opportunities and new challenges, respectively.\nThe first part will introduce some tips and tools for statisticians to use Great Lakes more effectively and will include a demonstration of the ```batchtools``` R package which can greatly simplify and organize the process of running numerical simulations in an HPC setting.\nThe second part will be a town hall regarding proposed policies for our account on Great Lakes. Because the department’s allocation is primarily used by students, department leadership has invited the PhD student council’s computing committee to propose specific policies for this new resource, and we want to get feedback on our policy proposal from current graduate students. If you use (or might use) Flux and/or Great Lakes, we want to hear from you! Our goal is to craft a policy that lets heavy users get their work done while making the experience of lighter users as smooth as possible.\nIf you’re interested in following along the demonstrations in the first part, you need to ensure you’re able to log-on to Great Lakes (```ssh uniqname@greatlakes.arc-ts.umich.edu```). You may also wish to review this wiki page on using batchtools on Great Lakes and you can install ```batchtools``` locally so that you can see a demonstration of how it works. Contact [stat-phd-council-computing@umich.edu](stat-phd-council-computing@umich.edu) with any questions.","tags":[],"title":"Navigating the Transition from Flux to Great Lakes: New tools and policy town hall","type":"talk"},{"authors":["Ziping Xu"],"categories":null,"content":"","date":1573057800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"3af4adaabe529f9570ffabcb957e1cdd","permalink":"https://umichstatistics.github.io/ComputingClub/talk/cpython/","publishdate":"2019-09-25T15:16:15-04:00","relpermalink":"/ComputingClub/talk/cpython/","section":"talk","summary":"''Cython is an optimising static compiler for both the Python programming language and the extended Cython programming language (based on Pyrex). It makes writing C extensions for Python as easy as Python itself.''---[Cython website](https://cython.org/)","tags":[],"title":"Accelerating Python using Cython","type":"talk"},{"authors":["Jeffrey Regier"],"categories":null,"content":"","date":1571848200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"5a57761e728210bb67200f27204207e6","permalink":"https://umichstatistics.github.io/ComputingClub/talk/julia/","publishdate":"2019-09-25T15:16:15-04:00","relpermalink":"/ComputingClub/talk/julia/","section":"talk","summary":"''Julia in a Nutshell---**Julia is fast!**\nJulia was designed from the beginning for high performance. Julia programs compile to efficient native code for multiple platforms via LLVM.\n**Dynamic.**\nJulia is dynamically-typed, feels like a scripting language, and has good support for interactive use.\n**Optionally typed.**\nJulia has a rich language of descriptive datatypes, and type declarations can be used to clarify and solidify programs.\n**General.**\nJulia uses multiple dispatch as a paradigm, making it easy to express many object-oriented and functional programming patterns. The standard library provides asynchronous I/O, process control, logging, profiling, a package manager, and more.\n**Easy to use.**\nJulia has high level syntax, making it an accessible language for programmers from any background or experience level.\n**Open source.**\nJulia is free for everyone to use, and all source code is publicly viewable on GitHub. ''---[Julia website](https://julialang.org/)","tags":[],"title":"The Julia language","type":"talk"},{"authors":["Simon Fontaine"],"categories":null,"content":"","date":1570638600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"467270c8eb0bbafce29fa13db51a95e9","permalink":"https://umichstatistics.github.io/ComputingClub/talk/website/","publishdate":"2019-09-25T15:16:15-04:00","relpermalink":"/ComputingClub/talk/website/","section":"talk","summary":"In a workshop-type presentation, you will learn how to build a simple academic personal website based on the Academic theme by the Hugo engine as well as hosting it on GitHub Pages or UMich personal space.","tags":["Website","Markdown"],"title":"Building \u0026 Hosting a Simple Academic Website","type":"talk"},{"authors":["Dan Kessler"],"categories":null,"content":"","date":1570033800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"a5aef24b959e024d1651bca037126c08","permalink":"https://umichstatistics.github.io/ComputingClub/talk/git/","publishdate":"2019-09-25T15:16:15-04:00","relpermalink":"/ComputingClub/talk/git/","section":"talk","summary":"While there are many online tutorials on how to use git, few attemp to teach what really happens behind the common commands. Understanding the differences and interactions between commited, staged and working file status as well as between local and remote repositories is essential to any git user in order to engage in adequate and pleasant version control.","tags":[],"title":"Git: a deeper perspective","type":"talk"},{"authors":["Simon Fontaine"],"categories":[],"content":"With the recent creation of the Statistics Computing Club, having a platform to share news, contents and resources was a priority.\nThe site is functionnal but still under construction, so please report issues to the GitHub repository to help us improve the site. Also, your comments and suggestions are more than welcome, so feel free to contact us!\nThe Committee is still looking for presenters for this fall\u0026rsquo;s meetings. You don\u0026rsquo;t need to be an expert of the topic you\u0026rsquo;ll present; providing exposure to a tool you find useful, to a package you think may help others or to some research methodology may be relevant to many other members! If you feel like presenting, we invite you to complete this form.\n","date":1569290776,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569439601,"objectID":"9c8fc5dc75abc298a528bb2179079a1e","permalink":"https://umichstatistics.github.io/ComputingClub/post/welcome/","publishdate":"2019-09-23T22:06:16-04:00","relpermalink":"/ComputingClub/post/welcome/","section":"post","summary":"With the recent creation of the Statistics Computing Club, having a platform to share news, contents and resources was a priority.\nThe site is functionnal but still under construction, so please report issues to the GitHub repository to help us improve the site. Also, your comments and suggestions are more than welcome, so feel free to contact us!\nThe Committee is still looking for presenters for this fall\u0026rsquo;s meetings. You don\u0026rsquo;t need to be an expert of the topic you\u0026rsquo;ll present; providing exposure to a tool you find useful, to a package you think may help others or to some research methodology may be relevant to many other members!","tags":["Club"],"title":"Welcome to the Computing club's new website","type":"post"},{"authors":["Derek Hansen"],"categories":null,"content":"","date":1568835000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674596622,"objectID":"52768db74e73cc94710d2441f091bcf6","permalink":"https://umichstatistics.github.io/ComputingClub/talk/intro_purr/","publishdate":"2019-09-23T21:22:29-05:00","relpermalink":"/ComputingClub/talk/intro_purr/","section":"talk","summary":"Presentation of the Computing club and discussion of its purpose and means. Presentation of the R package `purrr` for functional programming.","tags":["Club","R","Functional programming"],"title":"Informational meeting \u0026 Functional Programming in R with purrr","type":"talk"}]